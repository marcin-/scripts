#!/usr/bin/python
# -*- coding: utf-8 -*-
#
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# Please read the COPYING file.
#

import os
import sys
import time
import shutil
import subprocess

import pisi

from buildfarm import utils
from buildfarm import queuemanager
from buildfarm.config import configuration as conf

class UpdatesManager:
    def __init__(self):
        self.local_url  = utils.get_local_repository_url()      # local work repo
        self.local_git  = utils.get_local_git_repository_url()  # local git copy 

        self.final_queue = []

        self.new = []
        self.removed = []
        self.updated = []

        self.__check_diffs()
        
        if self.removed: self.__delete_files()
        if self.new:
            self.__copy_files("self.new")
            self.final_queue.extend(self.get_new_packages())
        if self.updated:
            self.__copy_files("self.updated")
            self.final_queue.extend(self.get_updated_packages())

        if self.removed or self.new or self.updated:
            try: 
                utils.update_local_repo_index()
            except pisi.pxml.xmlfile.Error, e:
                print "New/Updated packages:"
                print "\n".join(self.get_new_packages() + self.get_updated_packages())
                print "ERROR:", e
                sys.exit(1)

    def __check_diffs(self):
        src = {}
        dst = {}
        len_git_path = len(self.local_git)
        len_url_path = len(self.local_url)

        for root, dirs, files in os.walk(self.local_git):
            if root.startswith(os.path.join(self.local_git, ".git")): continue
            for f in files:
                src[os.path.join(root[len_git_path + 1:], f)] = time.ctime(os.path.getmtime(os.path.join(root, f)))
        if ".gitignore" in src: del src[".gitignore"]
        for root, dirs, files in os.walk(self.local_url):
            for f in files:
                dst[os.path.join(root[len_url_path + 1:], f)] = time.ctime(os.path.getmtime(os.path.join(root, f)))
         
        for f in src:
            try:
                if not src[f] == dst[f]: self.updated.append(f)
                del dst[f]
            except KeyError:
                self.new.append(f)
        for f in self.new: del src[f]

        self.removed.extend(sorted(dst.keys()))
    
    def __delete_files(self):
        dirs = []
        for f in self.removed:
            print "Removing file: %s" % os.path.join(self.local_url, f)
            os.remove(os.path.join(self.local_url, f))
            if not os.path.dirname(f) in dirs: dirs.append(os.path.dirname(os.path.join(self.local_url, f)))
        self.__delete_dirs(dirs)
    
    def __delete_dirs(self, paths):
        for path in paths:
            if os.path.isdir(path) and not os.listdir(path):
                print "Removing empty dir: %s" % path
                os.rmdir(path)

    def __copy_files(self, source):
        for f in sorted(eval(source)):
            if not os.path.isdir(os.path.dirname(os.path.join(self.local_url, f))):
                os.makedirs(os.path.dirname(os.path.join(self.local_url, f)))
            print "Copying file: %s to %s" % (f, self.local_url)
            shutil.copy2(os.path.join(self.local_git, f), os.path.join(self.local_url, f))
       
    def get_new_packages(self):
        return [os.path.join(self.local_url, f) for f in self.new if f.endswith("/pspec.xml")]

    def get_updated_packages(self):
        return [os.path.join(self.local_url, f) for f in self.updated if f.endswith("/pspec.xml")]
    
    def manage(self):
        print "Appending %s/waitqueue" % conf.workdir
        with open("%s/waitqueue" % conf.workdir) as f:
            self.final_queue.extend([pspec for pspec in f.read().splitlines() if not pspec in self.final_queue])
        print "Appending %s/workqueue" % conf.workdir
        with open("%s/workqueue" % conf.workdir) as f:
            self.final_queue.extend([pspec for pspec in f.read().splitlines() if not pspec in self.final_queue])

        for pspec in self.final_queue[:]:
            spec = pisi.specfile.SpecFile(pspec)

            # First the release check
            expected_pisi_file = os.path.join(utils.get_compiled_packages_directory(), \
                    utils.get_expected_file_name(spec))
            #print expected_pisi_file
            if os.path.exists(expected_pisi_file):
                self.final_queue.remove(pspec)
                #self.same_release_updates.append(pspec)
                continue

            # Now the architecture check
            if utils.is_arch_excluded(spec):
                self.final_queue.remove(pspec)
                #self.excluded_arch_packages.append(pspec)

        print "Writing %s/workqueue" % conf.workdir
        open("%s/workqueue" % conf.workdir, "w").write("\n".join(self.final_queue))
        utils.clean_waitqueue()

        utils.index_workqueue(self.final_queue)

class RepositoryManager:
    def __init__(self):
        self.local_pspec_repo = utils.get_local_repository_url()
        self.queue_manager = queuemanager.QueueManager()

        self.output = []

        self.final_queue = []
        self.new_packages = []
        self.updated_packages = []
        self.same_release_updates = []
        self.excluded_arch_packages = []

        if conf.scm == "svn":
            print "\nUpdating repository %s" % (utils.get_local_repository_url())
            process = subprocess.Popen(["svn", "up", self.local_pspec_repo],
                                       stdout=subprocess.PIPE,
                                       stderr=subprocess.STDOUT)
        elif conf.scm == "git":
            print "\nUpdating repository %s" % (utils.get_local_git_repository_url())
            oldwd = os.getcwd()
            os.chdir(utils.get_local_git_repository_url())
            process = subprocess.Popen(["git", "pull"],
                                       stdout=subprocess.PIPE,
                                       stderr=subprocess.STDOUT)
            os.chdir(oldwd)
        self.output = process.communicate()[0]

        if process.returncode != 0 and conf.scm == "svn":
            print "A problem with SVN occurred while updating repository, exiting."
            sys.exit(process.returncode)
        elif conf.scm == "svn":
            # List of lists
            self.output = [line.split() for line in self.output.split("\n") if line]
        elif conf.scm == "git":
            pass # TODO

    def get_changes(self, commit_type, search_for=""):
        results = []
        for line in self.output:
            if line[0] == commit_type and search_for in line[1]:
                results.append(line[1])

        return results

    def manage(self):
        self.new_packages = self.get_changes("A", "pspec.xml")
        self.updated_packages = self.get_changes("U", "pspec.xml")

        # Generate the biggest possible queue
        self.final_queue.extend(self.new_packages)
        self.final_queue.extend(self.updated_packages)
        self.final_queue.extend(self.queue_manager.get_work_queue())
        self.final_queue = list(set(self.final_queue))

        # Now we'll filter out the excludearch and release-stayed-the-same
        # packages.

        for pspec in self.final_queue[:]:
            if not os.path.exists(pspec):
                print "Warning: %s doesn't exist, removing from the queue." % pspec
                self.final_queue.remove(pspec)
                continue

            spec = pisi.specfile.SpecFile(pspec)
            # First the release check
            expected_pisi_file = os.path.join(utils.get_compiled_packages_directory(), \
                    utils.get_expected_file_name(spec))
            if os.path.exists(expected_pisi_file):
                self.final_queue.remove(pspec)
                self.same_release_updates.append(pspec)
                # Not incrementing the release will bypass the arch test
                continue

            # Now the architecture check
            if utils.is_arch_excluded(spec):
                self.final_queue.remove(pspec)
                self.excluded_arch_packages.append(pspec)

        # Finally merge back the new queue
        self.queue_manager.set_work_queue(self.final_queue)

    def dump_summary(self):
        if self.final_queue:
            utils.print_header("List of packages to be built:")
            print "\n".join(self.final_queue)

        if self.excluded_arch_packages:
            utils.print_header("List of ignored packages because of architecture mismatch:")
            print "\n".join(self.excluded_arch_packages)

        if self.same_release_updates:
            utils.print_header("List of ignored packages caused by a missing history update:")
            print "\n".join(self.same_release_updates)



# Main program

if __name__ == "__main__":

    if conf.scm == "git":
        print "\nUpdating repository %s" % (utils.get_local_git_repository_url())
        oldwd = os.getcwd()
        os.chdir(utils.get_local_git_repository_url())
        process = subprocess.Popen(["git", "pull"],
                                   stdout=subprocess.PIPE,
                                   stderr=subprocess.STDOUT)
        print process.communicate()[0]
        if process.returncode != 0:
            print "A problem with GIT occurred while updating repository, exiting."
            sys.exit(process.returncode)
        os.chdir(oldwd)
        um = UpdatesManager()
        um.manage()
        sys.exit(0)

    # Create RepositoryManager
    repository_manager = RepositoryManager()

    # Print current workqueue/waitqueue
    repository_manager.queue_manager.dump_work_queue()
    repository_manager.queue_manager.dump_wait_queue()

    repository_manager.manage()
    repository_manager.dump_summary()
